{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SP500 Stock Demo — Notebook 06: Streamlit App (Snowflake)\n",
        "\n",
        "- Minimal app: select ticker and model version\n",
        "- Plot actual vs predicted returns\n",
        "- Show latest PSI per feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0) Streamlit app (Snowflake)\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "from snowflake.snowpark.functions import col\n",
        "\n",
        "# Attach to Snowflake session and set context\n",
        "session = get_active_session()\n",
        "session.sql(\"USE DATABASE SP500_STOCK_DEMO\").collect()\n",
        "session.sql(\"USE SCHEMA DATA\").collect()\n",
        "\n",
        "st.set_page_config(page_title=\"SP500 ML Forecasts\", layout=\"wide\")\n",
        "st.title(\"SP500 Forecasts and Monitoring\")\n",
        "st.caption(\"Model: XGB_SP500_RET3M — training, inference, drift and explainability\")\n",
        "\n",
        "# Sidebar controls\n",
        "with st.sidebar:\n",
        "    st.header(\"Controls\")\n",
        "    # Model versions (from catalog)\n",
        "    models_df = session.sql(\"\"\"\n",
        "        SELECT name, versions\n",
        "        FROM DATA.SNOWFLAKE_ML_MODELS\n",
        "        WHERE name = 'XGB_SP500_RET3M'\n",
        "    \"\"\").to_pandas()\n",
        "    versions = []\n",
        "    if not models_df.empty:\n",
        "        import ast as _ast\n",
        "        versions = _ast.literal_eval(models_df.iloc[0]['VERSIONS'])\n",
        "    selected_version = st.selectbox(\"Model version\", options=versions if versions else [\"V_1\"])\n",
        "\n",
        "    # Data source for chart\n",
        "    source_mode = st.radio(\n",
        "        \"Prediction source\",\n",
        "        options=[\"Existing predictions\", \"On-demand scoring\"],\n",
        "        index=0,\n",
        "        help=\"Use persisted predictions or run the selected model on-the-fly for the range\"\n",
        "    )\n",
        "\n",
        "    # Ticker choices\n",
        "    try:\n",
        "        tickers = session.table('SP500_TICKERS').select('TICKER').to_pandas()['TICKER'].tolist()\n",
        "    except Exception:\n",
        "        tickers = session.table('PRICE_FEATURES').select('TICKER').distinct().to_pandas()['TICKER'].tolist()\n",
        "    ticker = st.selectbox(\"Ticker\", options=sorted(tickers)[:500])\n",
        "\n",
        "    # Date range defaults from PRICE_FEATURES\n",
        "    bounds = session.sql(\"SELECT MIN(TS) AS MN, MAX(TS) AS MX FROM PRICE_FEATURES\").collect()[0]\n",
        "    min_ts = pd.to_datetime(bounds[\"MN\"]) if bounds[\"MN\"] is not None else pd.Timestamp.today() - pd.Timedelta(days=90)\n",
        "    max_ts = pd.to_datetime(bounds[\"MX\"]) if bounds[\"MX\"] is not None else pd.Timestamp.today()\n",
        "    start_date = st.date_input(\"Start date\", value=(max_ts - pd.Timedelta(days=30)).date(), min_value=min_ts.date(), max_value=max_ts.date())\n",
        "    end_date = st.date_input(\"End date\", value=max_ts.date(), min_value=min_ts.date(), max_value=max_ts.date())\n",
        "\n",
        "    run_button = st.button(\"Update view\")\n",
        "\n",
        "# Helper to fetch predictions\n",
        "def load_existing_predictions(sym: str, start_d: pd.Timestamp, end_d: pd.Timestamp) -> pd.DataFrame:\n",
        "    sp = (\n",
        "        session.table('PREDICTIONS_SP500_RET3M')\n",
        "               .filter((col('TICKER') == sym) & (col('TS') >= pd.Timestamp(start_d)) & (col('TS') <= pd.Timestamp(end_d)))\n",
        "               .sort(col('TS'))\n",
        "    )\n",
        "    return sp.to_pandas()\n",
        "\n",
        "# Helper to on-demand score via registry\n",
        "def score_on_demand(sym: str, start_d: pd.Timestamp, end_d: pd.Timestamp, version: str) -> pd.DataFrame:\n",
        "    from snowflake.ml.registry import Registry\n",
        "    feature_cols = ['RET_1','SMA_5','SMA_20','VOL_20','RSI_PROXY','VOLUME','CLOSE']\n",
        "    reg = Registry(session=session, database_name='SP500_STOCK_DEMO', schema_name='DATA')\n",
        "    mv = reg.get_model('XGB_SP500_RET3M').version(version)\n",
        "    feats = (\n",
        "        session.table('PRICE_FEATURES')\n",
        "               .filter((col('TICKER') == sym) & (col('TS') >= pd.Timestamp(start_d)) & (col('TS') <= pd.Timestamp(end_d)))\n",
        "               .sort(col('TS'))\n",
        "    )\n",
        "    preds_sp = mv.run(feats, function_name='PREDICT')\n",
        "    return preds_sp.to_pandas()\n",
        "\n",
        "# Main panels\n",
        "tab_overview, tab_preds, tab_drift, tab_explain = st.tabs([\"Overview\", \"Predictions\", \"Drift\", \"Explainability\"])\n",
        "\n",
        "# Compute datasets for the selected controls\n",
        "if run_button or True:\n",
        "    start_ts = pd.to_datetime(start_date)\n",
        "    end_ts = pd.to_datetime(end_date) + pd.Timedelta(days=0, hours=23, minutes=59)\n",
        "\n",
        "    # Load predictions\n",
        "    try:\n",
        "        if source_mode == \"Existing predictions\":\n",
        "            preds_pd = load_existing_predictions(ticker, start_ts, end_ts)\n",
        "        else:\n",
        "            preds_pd = score_on_demand(ticker, start_ts, end_ts, selected_version)\n",
        "    except Exception as e:\n",
        "        preds_pd = pd.DataFrame()\n",
        "        st.warning(f\"Could not load predictions: {e}\")\n",
        "\n",
        "    # Join with CLOSE for context\n",
        "    try:\n",
        "        feats_pd = (\n",
        "            session.table('PRICE_FEATURES')\n",
        "                   .filter((col('TICKER') == ticker) & (col('TS') >= pd.Timestamp(start_ts)) & (col('TS') <= pd.Timestamp(end_ts)))\n",
        "                   .select('TICKER','TS','CLOSE')\n",
        "                   .sort(col('TS'))\n",
        "                   .to_pandas()\n",
        "        )\n",
        "    except Exception:\n",
        "        feats_pd = pd.DataFrame(columns=['TICKER','TS','CLOSE'])\n",
        "\n",
        "    merged = preds_pd.merge(feats_pd, on=['TICKER','TS'], how='left') if not preds_pd.empty else feats_pd\n",
        "\n",
        "    # Overview KPIs\n",
        "    with tab_overview:\n",
        "        c1, c2, c3, c4 = st.columns(4)\n",
        "        num_rows = int(len(merged)) if merged is not None else 0\n",
        "        avg_pred = float(merged['PREDICTED_RETURN'].mean()) if 'PREDICTED_RETURN' in merged else 0.0\n",
        "        std_pred = float(merged['PREDICTED_RETURN'].std()) if 'PREDICTED_RETURN' in merged else 0.0\n",
        "        c1.metric(\"Rows\", f\"{num_rows:,}\")\n",
        "        c2.metric(\"Avg predicted\", f\"{avg_pred:.5f}\")\n",
        "        c3.metric(\"Std predicted\", f\"{std_pred:.5f}\")\n",
        "        c4.metric(\"Model version\", selected_version)\n",
        "        st.divider()\n",
        "        st.subheader(f\"{ticker} — Predictions (selected window)\")\n",
        "        if not merged.empty and 'PREDICTED_RETURN' in merged:\n",
        "            chart_df = merged[['TS','PREDICTED_RETURN']].set_index('TS')\n",
        "            st.line_chart(chart_df)\n",
        "        else:\n",
        "            st.info(\"No predictions available for the selection.\")\n",
        "\n",
        "    # Predictions table and close context\n",
        "    with tab_preds:\n",
        "        st.subheader(\"Detail table\")\n",
        "        if not merged.empty:\n",
        "            st.dataframe(merged.sort_values('TS').reset_index(drop=True))\n",
        "            st.subheader(\"Close price context\")\n",
        "            if 'CLOSE' in merged:\n",
        "                st.line_chart(merged[['TS','CLOSE']].set_index('TS'))\n",
        "        else:\n",
        "            st.info(\"No data to display for current filters.\")\n",
        "\n",
        "    # Drift panel: show latest PSI table if exists\n",
        "    with tab_drift:\n",
        "        st.subheader(\"Recent feature drift (PSI)\")\n",
        "        try:\n",
        "            psi_pd = session.table('DRIFT_PSI_SP500').to_pandas()\n",
        "            if not psi_pd.empty:\n",
        "                st.dataframe(psi_pd.sort_values('FEATURE').reset_index(drop=True))\n",
        "            else:\n",
        "                st.info(\"PSI table is empty.\")\n",
        "        except Exception:\n",
        "            st.info(\"PSI table not found. Run the inference/monitoring notebook to generate it.\")\n",
        "\n",
        "    # Explainability: show global SHAP importances if logged\n",
        "    with tab_explain:\n",
        "        st.subheader(\"Global feature importance (mean |SHAP|)\")\n",
        "        try:\n",
        "            shap_pd = session.table('FEATURE_SHAP_GLOBAL_TOP').to_pandas()\n",
        "            if not shap_pd.empty:\n",
        "                topn = shap_pd.sort_values('mean_abs_shap', ascending=False).head(15)\n",
        "                st.bar_chart(topn.set_index('feature')['mean_abs_shap'])\n",
        "                st.dataframe(topn.reset_index(drop=True))\n",
        "            else:\n",
        "                st.info(\"No SHAP importance table found.\")\n",
        "        except Exception:\n",
        "            st.info(\"No SHAP importance table found.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
