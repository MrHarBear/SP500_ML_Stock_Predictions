{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SP500 Stock Demo — Notebook 05: Incremental Retraining and Compare\n",
        "\n",
        "Use this notebook as a live “how models evolve” demo: we shift the time window forward, retrain on fresher data, and compare the new model with the previously registered version. If the new model wins, we register a new version and set it as default.\n",
        "\n",
        "What you will show (talk track)\n",
        "- Why retrain: data and regimes change; we regularly refresh models on the latest window\n",
        "- How we define windows: old cutoff at max(TS) − 30 days; new cutoff shifts forward by 15 days\n",
        "- What changes: data between (max(TS) − 30d, max(TS) − 15d] moves from test into train; the newest 15 days becomes the new test\n",
        "- How we compare: compute RMSE/R² on aligned test windows and only register if improved\n",
        "\n",
        "Outputs\n",
        "- Printed cutoffs for old vs new training/test windows\n",
        "- Side-by-side metrics for old (registry) vs new (freshly trained)\n",
        "- Optional new registry version if improved\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0) Imports and session/context\n",
        "# - Attach to the active Snowflake session used by this notebook\n",
        "# - Set warehouse, database, schema\n",
        "# - Load ML libraries for retraining and registry\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "from snowflake.snowpark.functions import col, lead, avg, sqrt\n",
        "from snowflake.snowpark.functions import abs as sp_abs\n",
        "from snowflake.snowpark.functions import pow as sp_pow\n",
        "from snowflake.snowpark import Window\n",
        "from snowflake.ml.modeling.pipeline import Pipeline\n",
        "from snowflake.ml.modeling.xgboost import XGBRegressor\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "session = get_active_session()\n",
        "session.sql(\"USE WAREHOUSE DEMO_WH_M\").collect()\n",
        "session.sql(\"USE DATABASE SP500_STOCK_DEMO\").collect()\n",
        "session.sql(\"USE SCHEMA DATA\").collect()\n",
        "\n",
        "# Note: retraining uses the same feature table `PRICE_FEATURES` as Notebook 03.\n",
        "# If you enriched features (V2), ensure they are present in `PRICE_FEATURES`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1 — Define dataset and rolling windows\n",
        "\n",
        "- We reuse `PRICE_FEATURES` and construct the same 3‑month-ahead label (`TARGET_PCT_3M`) as in Notebook 03.\n",
        "- Old window: cutoff_old = max(TS) − 30 days; train_old = TS < cutoff_old; test_old = TS ≥ cutoff_old.\n",
        "- New window: cutoff_new = max(TS) − 15 days; train_new = TS < cutoff_new; test_new = TS ≥ cutoff_new.\n",
        "- What’s “new data”: rows where TS ∈ (cutoff_old, cutoff_new] move from the old test into the new train; rows with TS ∈ (cutoff_new, max(TS)] form the new test.\n",
        "\n",
        "Demo tip: call out how little code change is needed to move the window forward while leaving the feature and target logic intact.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) Define base dataset and time windows\n",
        "# - Reuse PRICE_FEATURES and create the same label as in Notebook 03\n",
        "hourly = session.table('PRICE_FEATURES')\n",
        "win_order = Window.partition_by('TICKER').order_by(col('TS'))\n",
        "horizon_hours = 378  # ~3 months ahead label\n",
        "\n",
        "# Build labeled dataset\n",
        "ds = (\n",
        "    hourly\n",
        "    .with_column('FUT_CLOSE', lead(col('CLOSE'), horizon_hours).over(win_order))  # future close\n",
        "    .with_column('TARGET_PCT_3M', (col('FUT_CLOSE')/col('CLOSE') - 1))           # 3M-ahead return\n",
        "    .drop('FUT_CLOSE')\n",
        "    .filter(col('TARGET_PCT_3M').is_not_null())\n",
        ")\n",
        "\n",
        "# Compute cutoffs relative to the labeled dataset's max TS (avoids empty test due to lead horizon)\n",
        "from datetime import timedelta\n",
        "from snowflake.snowpark.functions import max as sp_max\n",
        "max_ts_ds = ds.select(sp_max(col('TS')).alias('mx')).collect()[0]['MX']\n",
        "\n",
        "# Old split used in V_1 (train_old/test_old)\n",
        "cutoff_old = max_ts_ds - timedelta(days=30)\n",
        "train_old = ds.filter(col('TS') < cutoff_old)\n",
        "test_old = ds.filter(col('TS') >= cutoff_old)\n",
        "\n",
        "# New split (shift forward by 15 days): move some recent data from test_old into train_new\n",
        "cutoff_new = max_ts_ds - timedelta(days=15)\n",
        "train_new = ds.filter(col('TS') < cutoff_new)\n",
        "test_new = ds.filter(col('TS') >= cutoff_new)\n",
        "\n",
        "print({'cutoff_old': cutoff_old, 'cutoff_new': cutoff_new,\n",
        "       'train_old_rows': train_old.count(), 'test_old_rows': test_old.count(),\n",
        "       'train_new_rows': train_new.count(), 'test_new_rows': test_new.count()})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2 — Retrain on the new window\n",
        "\n",
        "- Fixed XGB parameters (keeps the retrain fast/stable for demos); you can swap in the “best” config from Notebook 03.\n",
        "- Train set is `TS < cutoff_new`; Test set for comparison later is `TS ≥ cutoff_new`.\n",
        "- Demo tip: emphasize we do not change feature definitions or label—only the time window slides.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) Retrain with fixed XGB params (fast/stable demo setup)\n",
        "feature_cols = ['RET_1','SMA_5','SMA_20','VOL_20','RSI_PROXY','VOLUME','CLOSE']\n",
        "label_col = 'TARGET_PCT_3M'\n",
        "output_col = 'PREDICTED_RETURN'\n",
        "\n",
        "xgb = XGBRegressor(\n",
        "    n_estimators=200,     # consider 400–800 + early stopping for production\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    input_cols=feature_cols,\n",
        "    label_cols=[label_col],\n",
        "    output_cols=[output_col],\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "pipe = Pipeline(steps=[('xgb', xgb)])\n",
        "model_new = pipe.fit(train_new)\n",
        "print('Retrained on train_new (TS < cutoff_new).')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3 — Evaluate and compare versions\n",
        "\n",
        "- We evaluate the previous registry version (V_1) on `test_old` and the newly trained model on `test_new`.\n",
        "- Both metrics use RMSE and R² computed in-database to avoid data movement.\n",
        "- Demo tip: highlight you can add additional splits (rolling CV) and richer metrics as needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3) Evaluate and compare with previous registered version (using snowflake.ml.modeling.metrics)\n",
        "from snowflake.ml.modeling.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Helper to compute metrics with built-ins (see docs)\n",
        "# https://docs.snowflake.com/en/developer-guide/snowpark-ml/reference/latest/modeling#snowflake-ml-modeling-metrics\n",
        "\n",
        "def compute_metrics(df, y_col, yhat_col):\n",
        "    rmse = mean_squared_error(df=df, y_true_col_names=y_col, y_pred_col_names=yhat_col, squared=False)\n",
        "    r2 = r2_score(df=df, y_true_col_name=y_col, y_pred_col_name=yhat_col)\n",
        "    return {'rmse': rmse, 'r2': r2}\n",
        "\n",
        "# Score previous registry version on its old test window\n",
        "pred_old = Registry(session=session, database_name='SP500_STOCK_DEMO', schema_name='DATA')\\\n",
        "    .get_model('XGB_SP500_RET3M').version('V_1').run(test_old, function_name='PREDICT')\n",
        "metrics_old = compute_metrics(pred_old.select(label_col, output_col), label_col, output_col)\n",
        "\n",
        "# Score newly retrained model on the current test window\n",
        "pred_new = model_new.predict(test_new)\n",
        "metrics_new = compute_metrics(pred_new.select(label_col, output_col), label_col, output_col)\n",
        "print({'old': metrics_old, 'new': metrics_new})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4 — Register if improved (idempotent demo flow)\n",
        "\n",
        "- We only log a new registry version when the new model’s RMSE improves over the old.\n",
        "- Version naming increments numerically (V_1, V_2, ...). Default is updated to the new version on success.\n",
        "- Demo tip: This flow is safe to re-run; if no improvement, it skips registration gracefully.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4) Register new version if improved\n",
        "reg = Registry(session=session, database_name='SP500_STOCK_DEMO', schema_name='DATA')\n",
        "model_name = 'XGB_SP500_RET3M'\n",
        "\n",
        "if metrics_new['rmse'] < metrics_old['rmse']:\n",
        "    models_df = reg.show_models()\n",
        "    if models_df.empty or model_name not in models_df['name'].to_list():\n",
        "        version = 'V_1'\n",
        "    else:\n",
        "        import ast, builtins\n",
        "        max_v = builtins.max([int(v.split('_')[-1]) for v in ast.literal_eval(models_df.loc[models_df['name']==model_name,'versions'].values[0])])\n",
        "        version = f'V_{max_v+1}'\n",
        "    mv = reg.log_model(\n",
        "        model_new,\n",
        "        model_name=model_name,\n",
        "        version_name=version,\n",
        "        conda_dependencies=['snowflake-ml-python'],\n",
        "        comment='Incremental retrain (shifted window) — train_new vs test_new',\n",
        "        metrics={'rmse': metrics_new['rmse'], 'r2': metrics_new['r2']},\n",
        "        options={'relax_version': False}\n",
        "    )\n",
        "    reg.get_model(model_name).default = version\n",
        "    print({'registered': version})\n",
        "else:\n",
        "    print('No registration: new model did not improve RMSE')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How to reuse this notebook as a repeatable asset\n",
        "\n",
        "What this retrains on\n",
        "- Source: `SP500_STOCK_DEMO.DATA.PRICE_FEATURES`\n",
        "- Label: `TARGET_PCT_3M = lead(CLOSE, 378h)/CLOSE − 1` per `TICKER`\n",
        "- Old training/test: `TS < cutoff_old` / `TS ≥ cutoff_old` with `cutoff_old = max(TS) − 30d`\n",
        "- New training/test: `TS < cutoff_new` / `TS ≥ cutoff_new` with `cutoff_new = max(TS) − 15d`\n",
        "- New data: all rows with `TS ∈ (cutoff_old, cutoff_new]` that were previously in test now join training; the latest 15 days become the new test\n",
        "\n",
        "To rerun in future demos\n",
        "- No manual config if `PRICE_FEATURES` exists and `DEMO_WH_M` is available; the notebook auto-computes `max(TS)`.\n",
        "- If your account uses different objects, change once at the top:\n",
        "  - Warehouse/DB/Schema in the session setup\n",
        "  - Table name for features (`PRICE_FEATURES`)\n",
        "- Optional knobs:\n",
        "  - Shift sizes: change 30d and 15d to fit your cadence\n",
        "  - Model params: use the best config from Notebook 03 or keep the fixed demo params\n",
        "  - Registration rule: switch from RMSE-only to a composite (e.g., RMSE and R²)\n",
        "\n",
        "Demo script (short)\n",
        "- “We roll the window forward by 15 days; yesterday’s test becomes today’s training. We retrain on `TS < cutoff_new`, evaluate on `TS ≥ cutoff_new`, compare against the last registered version on its original test, and only register a new version if it truly improves.”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create versioned predictions with ground truth and per-version monitors\n",
        "\n",
        "This section mirrors the reference flow: it scores a labeled recent slice for `V_1` and the latest registry version, persists per-version prediction tables with class/score/actuals, builds per-version baselines, and creates two monitors so Snowsight can compare V1 vs the latest.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5) Score labeled recent slice for V_1 and latest; persist per-version GT tables and baselines\n",
        "from snowflake.snowpark.functions import col\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "reg = Registry(session=session, database_name='SP500_STOCK_DEMO', schema_name='DATA')\n",
        "model_name = 'XGB_SP500_RET3M'\n",
        "\n",
        "# Discover versions\n",
        "models_df = reg.show_models()\n",
        "versions = []\n",
        "if not models_df.empty and model_name in models_df['name'].to_list():\n",
        "    import ast\n",
        "    versions = sorted(ast.literal_eval(models_df.loc[models_df['name']==model_name,'versions'].values[0]))\n",
        "latest_version = versions[-1] if versions else None\n",
        "print({'available_versions': versions, 'latest_version': latest_version})\n",
        "\n",
        "# Use the labeled dataset 'ds' (contains TARGET_PCT_3M)\n",
        "cutoff_common = session.sql(\"select dateadd('day', -60, max(TS)) as c from PRICE_FEATURES\").collect()[0]['C']\n",
        "ds_recent = ds.filter(col('TS') >= cutoff_common)\n",
        "\n",
        "# Helper: score version on labeled data and produce class/score/actuals table\n",
        "\n",
        "def score_with_labels(version_name: str, out_table: str):\n",
        "    mdl = reg.get_model(model_name).version(version_name)\n",
        "    scored = mdl.run(ds_recent, function_name='PREDICT')\n",
        "    tmp = f\"TMP_{out_table}\"\n",
        "    scored.write.save_as_table(tmp, mode='overwrite')\n",
        "    session.sql(f\"\"\"\n",
        "        CREATE OR REPLACE TABLE {out_table} AS\n",
        "        SELECT\n",
        "          TS,\n",
        "          TICKER,\n",
        "          PREDICTED_RETURN,\n",
        "          TARGET_PCT_3M AS ACTUAL_RETURN,\n",
        "          IFF(TARGET_PCT_3M > 0, 1, 0) AS ACTUAL_UP,\n",
        "          IFF(PREDICTED_RETURN > 0, 1, 0) AS PREDICTED_RESPONSE,\n",
        "          1.0/(1.0 + EXP(-5 * PREDICTED_RETURN)) AS PREDICTED_SCORE\n",
        "        FROM {tmp}\n",
        "        WHERE TARGET_PCT_3M IS NOT NULL\n",
        "    \"\"\").collect()\n",
        "    return out_table\n",
        "\n",
        "v1_table = None\n",
        "try:\n",
        "    v1_table = score_with_labels('V_1', 'PREDICTIONS_SP500_RET3M_V1_GT')\n",
        "    print({'scored_with_gt': 'V_1', 'table': v1_table})\n",
        "except Exception as e:\n",
        "    print('V_1 not available; skipping V1 scoring. Reason:', str(e))\n",
        "\n",
        "v2_table = None\n",
        "if latest_version and latest_version != 'V_1':\n",
        "    v2_table = score_with_labels(latest_version, 'PREDICTIONS_SP500_RET3M_V2_GT')\n",
        "    print({'scored_with_gt': latest_version, 'table': v2_table})\n",
        "\n",
        "# Baselines per-version (earliest 14 days)\n",
        "session.sql(\"USE WAREHOUSE DEMO_WH_M\").collect()\n",
        "session.sql(\"USE DATABASE SP500_STOCK_DEMO\").collect()\n",
        "session.sql(\"USE SCHEMA DATA\").collect()\n",
        "\n",
        "if v1_table:\n",
        "    session.sql(f\"\"\"\n",
        "        CREATE OR REPLACE TABLE BASELINE_PREDICTIONS_V1 AS\n",
        "        WITH b AS (SELECT MIN(TS) AS mn FROM {v1_table})\n",
        "        SELECT p.* FROM {v1_table} p, b\n",
        "        WHERE p.TS >= b.mn AND p.TS < DATEADD('day', 14, b.mn);\n",
        "    \"\"\").collect()\n",
        "\n",
        "if v2_table:\n",
        "    session.sql(f\"\"\"\n",
        "        CREATE OR REPLACE TABLE BASELINE_PREDICTIONS_V2 AS\n",
        "        WITH b AS (SELECT MIN(TS) AS mn FROM {v2_table})\n",
        "        SELECT p.* FROM {v2_table} p, b\n",
        "        WHERE p.TS >= b.mn AND p.TS < DATEADD('day', 14, b.mn);\n",
        "    \"\"\").collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- 6) Create per-version monitors with performance metrics enabled\n",
        "USE WAREHOUSE DEMO_WH_M;\n",
        "USE DATABASE SP500_STOCK_DEMO;\n",
        "USE SCHEMA DATA;\n",
        "\n",
        "-- V1 monitor (classification-style metrics enabled)\n",
        "CREATE OR REPLACE MODEL MONITOR SP500_RET3M_MONITOR_V1\n",
        "WITH \n",
        "  MODEL = SP500_STOCK_DEMO.DATA.XGB_SP500_RET3M,\n",
        "  VERSION = 'V_1',\n",
        "  FUNCTION = 'PREDICT',\n",
        "  SOURCE = SP500_STOCK_DEMO.DATA.PREDICTIONS_SP500_RET3M_V1_GT,\n",
        "  BASELINE = SP500_STOCK_DEMO.DATA.BASELINE_PREDICTIONS_V1,\n",
        "  WAREHOUSE = DEMO_WH_M,\n",
        "  REFRESH_INTERVAL = '1 DAY',\n",
        "  AGGREGATION_WINDOW = '7 DAYS',\n",
        "  TIMESTAMP_COLUMN = TS,\n",
        "  ID_COLUMNS = ('TICKER'),\n",
        "  PREDICTION_CLASS_COLUMNS = ('PREDICTED_RESPONSE'),\n",
        "  ACTUAL_CLASS_COLUMNS = ('ACTUAL_UP'),\n",
        "  PREDICTION_SCORE_COLUMNS = ('PREDICTED_SCORE');\n",
        "\n",
        "-- V2/latest monitor (adjust VERSION if your latest isn't V_2)\n",
        "CREATE OR REPLACE MODEL MONITOR SP500_RET3M_MONITOR_V2\n",
        "WITH \n",
        "  MODEL = SP500_STOCK_DEMO.DATA.XGB_SP500_RET3M,\n",
        "  VERSION = 'V_2',\n",
        "  FUNCTION = 'PREDICT',\n",
        "  SOURCE = SP500_STOCK_DEMO.DATA.PREDICTIONS_SP500_RET3M_V2_GT,\n",
        "  BASELINE = SP500_STOCK_DEMO.DATA.BASELINE_PREDICTIONS_V2,\n",
        "  WAREHOUSE = DEMO_WH_M,\n",
        "  REFRESH_INTERVAL = '1 DAY',\n",
        "  AGGREGATION_WINDOW = '7 DAYS',\n",
        "  TIMESTAMP_COLUMN = TS,\n",
        "  ID_COLUMNS = ('TICKER'),\n",
        "  PREDICTION_CLASS_COLUMNS = ('PREDICTED_RESPONSE'),\n",
        "  ACTUAL_CLASS_COLUMNS = ('ACTUAL_UP'),\n",
        "  PREDICTION_SCORE_COLUMNS = ('PREDICTED_SCORE');\n",
        "\n",
        "SHOW MODEL MONITORS LIKE 'SP500_RET3M_MONITOR%';\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
