{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SP500 Stock Demo â€” Notebook 05: Incremental Retraining + Compare\n",
        "\n",
        "- Retrain model on most recent window\n",
        "- Register new version if metrics improve\n",
        "- Compare versions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0) Imports and session/context\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "from snowflake.snowpark.functions import col, lead, avg, sqrt\n",
        "from snowflake.snowpark.functions import abs as sp_abs\n",
        "from snowflake.snowpark.functions import pow as sp_pow\n",
        "from snowflake.snowpark import Window\n",
        "from snowflake.ml.modeling.pipeline import Pipeline\n",
        "from snowflake.ml.modeling.xgboost import XGBRegressor\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "session = get_active_session()\n",
        "session.sql(\"USE WAREHOUSE DEMO_WH_M\").collect()\n",
        "session.sql(\"USE DATABASE SP500_STOCK_DEMO\").collect()\n",
        "session.sql(\"USE SCHEMA DATA\").collect()\n",
        "\n",
        "# Use enriched features (V2 content in PRICE_FEATURES)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) Define base dataset and time windows\n",
        "hourly = session.table('PRICE_FEATURES')\n",
        "win_order = Window.partition_by('TICKER').order_by(col('TS'))\n",
        "horizon_hours = 378\n",
        "\n",
        "ds = (\n",
        "    hourly\n",
        "    .with_column('FUT_CLOSE', lead(col('CLOSE'), horizon_hours).over(win_order))\n",
        "    .with_column('TARGET_PCT_3M', (col('FUT_CLOSE')/col('CLOSE') - 1))\n",
        "    .drop('FUT_CLOSE')\n",
        "    .filter(col('TARGET_PCT_3M').is_not_null())\n",
        ")\n",
        "\n",
        "# Old split used in V_1\n",
        "cutoff_old = session.sql(\"select dateadd('day', -30, max(TS)) as c from PRICE_FEATURES\").collect()[0]['C']\n",
        "train_old = ds.filter(col('TS') < cutoff_old)\n",
        "test_old = ds.filter(col('TS') >= cutoff_old)\n",
        "\n",
        "# New split: shift the window forward by 15 days\n",
        "cutoff_new = session.sql(\"select dateadd('day', -15, max(TS)) as c from PRICE_FEATURES\").collect()[0]['C']\n",
        "train_new = ds.filter(col('TS') < cutoff_new)\n",
        "test_new = ds.filter(col('TS') >= cutoff_new)\n",
        "\n",
        "print({'cutoff_old': cutoff_old, 'cutoff_new': cutoff_new})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) Retrain with fixed XGB params\n",
        "feature_cols = ['RET_1','SMA_5','SMA_20','VOL_20','RSI_PROXY','VOLUME','CLOSE']\n",
        "label_col = 'TARGET_PCT_3M'\n",
        "output_col = 'PREDICTED_RETURN'\n",
        "\n",
        "xgb = XGBRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    input_cols=feature_cols,\n",
        "    label_cols=[label_col],\n",
        "    output_cols=[output_col],\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "pipe = Pipeline(steps=[('xgb', xgb)])\n",
        "model_new = pipe.fit(train_new)\n",
        "print('Retrained.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3) Evaluate and compare with previous registered version\n",
        "from snowflake.snowpark.functions import avg\n",
        "\n",
        "def compute_metrics(df, y_col, yhat_col):\n",
        "    rmse = df.select(sqrt(avg(sp_pow(col(y_col) - col(yhat_col), 2))).alias('rmse')).collect()[0]['RMSE']\n",
        "    mean_y = df.select(avg(col(y_col)).alias('mean_y')).collect()[0]['MEAN_Y']\n",
        "    sse = df.select(avg(sp_pow(col(y_col) - col(yhat_col), 2)).alias('mse')).collect()[0]['MSE']\n",
        "    sst = df.select(avg(sp_pow(col(y_col) - mean_y, 2)).alias('var')).collect()[0]['VAR']\n",
        "    r2 = 1.0 - (sse / sst if sst and sst != 0 else 0.0)\n",
        "    return {'rmse': rmse, 'r2': r2}\n",
        "\n",
        "pred_old = Registry(session=session, database_name='SP500_STOCK_DEMO', schema_name='DATA').get_model('XGB_SP500_RET3M').version('V_1').run(test_old, function_name='PREDICT')\n",
        "metrics_old = compute_metrics(pred_old.select(label_col, output_col), label_col, output_col)\n",
        "\n",
        "pred_new = model_new.predict(test_new)\n",
        "metrics_new = compute_metrics(pred_new.select(label_col, output_col), label_col, output_col)\n",
        "print({'old': metrics_old, 'new': metrics_new})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4) Register new version if improved\n",
        "reg = Registry(session=session, database_name='SP500_STOCK_DEMO', schema_name='DATA')\n",
        "model_name = 'XGB_SP500_RET3M'\n",
        "\n",
        "if metrics_new['rmse'] < metrics_old['rmse']:\n",
        "    models_df = reg.show_models()\n",
        "    if models_df.empty or model_name not in models_df['name'].to_list():\n",
        "        version = 'V_1'\n",
        "    else:\n",
        "        import ast, builtins\n",
        "        max_v = builtins.max([int(v.split('_')[-1]) for v in ast.literal_eval(models_df.loc[models_df['name']==model_name,'versions'].values[0])])\n",
        "        version = f'V_{max_v+1}'\n",
        "    mv = reg.log_model(\n",
        "        model_new,\n",
        "        model_name=model_name,\n",
        "        version_name=version,\n",
        "        conda_dependencies=['snowflake-ml-python'],\n",
        "        comment='Incremental retrain (shifted window)',\n",
        "        metrics={'rmse': metrics_new['rmse'], 'r2': metrics_new['r2']},\n",
        "        options={'relax_version': False}\n",
        "    )\n",
        "    reg.get_model(model_name).default = version\n",
        "    print({'registered': version})\n",
        "else:\n",
        "    print('No registration: new model did not improve RMSE')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
